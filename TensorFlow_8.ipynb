{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**당뇨병환자 분류**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.294118   0.487437   0.180328  ... -0.53117   -0.0333333  0.       ]\n",
      " [-0.882353  -0.145729   0.0819672 ... -0.766866  -0.666667   1.       ]\n",
      " [-0.0588235  0.839196   0.0491803 ... -0.492741  -0.633333   0.       ]\n",
      " ...\n",
      " [-0.411765   0.21608    0.180328  ... -0.857387  -0.7        1.       ]\n",
      " [-0.882353   0.266332  -0.0163934 ... -0.768574  -0.133333   0.       ]\n",
      " [-0.882353  -0.0653266  0.147541  ... -0.797609  -0.933333   1.       ]]\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('DataSet/diabetes.csv', delimiter = ',', dtype = np.float32)\n",
    "print(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 8) (759, 1)\n"
     ]
    }
   ],
   "source": [
    "xdata = xy[:,0:-1]\n",
    "ydata = xy[:,[-1]]\n",
    "print(xdata.shape, ydata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.78797144\n",
      "500 0.69929034\n",
      "1000 0.6541983\n",
      "1500 0.61999065\n",
      "2000 0.59363246\n",
      "2500 0.57318795\n",
      "3000 0.55719835\n",
      "3500 0.5445714\n",
      "4000 0.5344939\n",
      "4500 0.5263617\n",
      "5000 0.5197259\n",
      "5500 0.51425225\n",
      "6000 0.5096898\n",
      "6500 0.5058494\n",
      "7000 0.5025868\n",
      "7500 0.4997911\n",
      "8000 0.49737608\n",
      "8500 0.49527448\n",
      "9000 0.49343288\n",
      "9500 0.49180865\n",
      "10000 0.4903676\n",
      "정확도 :  0.76943344\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [None, 8])\n",
    "y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "w = tf.Variable(tf.random_normal([8,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "hf = tf.sigmoid(tf.matmul(x,w) + b)\n",
    "cost = -tf.reduce_mean(y*tf.log(hf) + (1-y)*tf.log(1-hf))\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "predicted = tf.cast(hf>0.5, tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype = tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        cv, _ = sess.run([cost, train], feed_dict = {x:xdata, y:ydata})\n",
    "        if step % 500 == 0 :\n",
    "            print(step, cv)\n",
    "            \n",
    "    cv, av = sess.run([predicted, accuracy], feed_dict = {x:xdata, y:ydata})\n",
    "    print(\"정확도 : \", av)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'DataSet/q_1.txt:1'\n",
      "b','\n",
      "[4, 10]\n",
      "[0, 0]\n",
      "[7, 4]\n",
      "[7, 22]\n",
      "[8, 16]\n",
      "[9, 10]\n",
      "[10, 18]\n",
      "[10, 26]\n",
      "[10, 34]\n",
      "[11, 17]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "myqueue = tf.train.string_input_producer(['DataSet/q_1.txt','DataSet/q_2.txt','DataSet/q_3.txt'], shuffle=False) #입력데이터를 자동으로 만들어주는 함수\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess = sess, coord = coord) # coord, threads 수식 항상 고정\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(myqueue)\n",
    "\n",
    "\n",
    "print(sess.run(key))\n",
    "print(sess.run(value))\n",
    "rd = [[0],[0]]\n",
    "for i in range(100) :\n",
    "    speed, dist = tf.decode_csv(value, record_defaults=rd)\n",
    "    if i % 10 == 0 :\n",
    "        print(sess.run([speed, dist]))\n",
    "coord.request_stop()\n",
    "coord.join(threads=threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "myqueue = tf.train.string_input_producer(['DataSet/q_1.txt','DataSet/q_2.txt','DataSet/q_3.txt'], shuffle=False) #입력데이터를 자동으로 만들어주는 함수\n",
    "\n",
    "\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(myqueue)\n",
    "record_defaults = [[-1],[999]]\n",
    "speed, dist = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "x_batch, y_batch = tf.train.batch([speed, dist], batch_size = 4)\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess = sess, coord = coord) # coord, threads 수식 항상 고정\n",
    "\n",
    "for i in range(100) :\n",
    "    x, y = sess.run([x_batch, y_batch])\n",
    "    # x와 y를 이용하여 모델링\n",
    "#     print(x,y)\n",
    "coord.request_stop()\n",
    "coord.join(threads=threads)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
