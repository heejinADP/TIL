{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price :  220\n",
      "dApple :  2.2\n",
      "dApple_num :  110\n",
      "dTax :  200\n"
     ]
    }
   ],
   "source": [
    "class MulLayer :\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x*y\n",
    "        return out\n",
    "    def backword(self, dout) : #dout에 1 전달\n",
    "        dx = dout*self.y\n",
    "        dy = dout*self.x\n",
    "        return dx, dy #dx: dapple_price, dy: dapple_tax\n",
    "        \n",
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price,tax)\n",
    "\n",
    "#backword\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backword(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backword(dapple_price)\n",
    "\n",
    "print(\"price : \", int(price))\n",
    "print(\"dApple : \", dapple)\n",
    "print(\"dApple_num : \", int(dapple_num))\n",
    "print(\"dTax : \", int(dtax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./DataSet/mnist/data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./DataSet/mnist/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./DataSet/mnist/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./DataSet/mnist/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"./DataSet/mnist/data\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 28*28])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([28*28, 256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(x,w1))\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1,w2))\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([256,10], stddev=0.01))\n",
    "model = tf.nn.relu(tf.matmul(L2,w3))\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch :      1 \n",
      "evg cost :  0.4302293468\n",
      "정확도 :  0.9475\n",
      "\n",
      "epoch :      2 \n",
      "evg cost :  0.1663434007\n",
      "정확도 :  0.9595\n",
      "\n",
      "epoch :      3 \n",
      "evg cost :  0.1180988522\n",
      "정확도 :  0.9706\n",
      "\n",
      "epoch :      4 \n",
      "evg cost :  0.0931614543\n",
      "정확도 :  0.9747\n",
      "\n",
      "epoch :      5 \n",
      "evg cost :  0.0763577245\n",
      "정확도 :  0.9766\n",
      "\n",
      "epoch :      6 \n",
      "evg cost :  0.0626177405\n",
      "정확도 :  0.9766\n",
      "\n",
      "epoch :      7 \n",
      "evg cost :  0.0540636675\n",
      "정확도 :  0.9741\n",
      "\n",
      "epoch :      8 \n",
      "evg cost :  0.0487965303\n",
      "정확도 :  0.9805\n",
      "\n",
      "epoch :      9 \n",
      "evg cost :  0.0420467645\n",
      "정확도 :  0.9802\n",
      "\n",
      "epoch :     10 \n",
      "evg cost :  0.0387631288\n",
      "정확도 :  0.9796\n",
      "\n",
      "epoch :     11 \n",
      "evg cost :  0.0349885001\n",
      "정확도 :  0.9788\n",
      "\n",
      "epoch :     12 \n",
      "evg cost :  0.0335329288\n",
      "정확도 :  0.9791\n",
      "\n",
      "epoch :     13 \n",
      "evg cost :  0.0285186489\n",
      "정확도 :  0.9809\n",
      "\n",
      "epoch :     14 \n",
      "evg cost :  0.0268952070\n",
      "정확도 :  0.9815\n",
      "\n",
      "epoch :     15 \n",
      "evg cost :  0.0276901433\n",
      "정확도 :  0.9807\n",
      "\n",
      "epoch :     16 \n",
      "evg cost :  0.0255499569\n",
      "정확도 :  0.9811\n",
      "\n",
      "epoch :     17 \n",
      "evg cost :  0.0242625670\n",
      "정확도 :  0.9818\n",
      "\n",
      "epoch :     18 \n",
      "evg cost :  0.0221529044\n",
      "정확도 :  0.9806\n",
      "\n",
      "epoch :     19 \n",
      "evg cost :  0.0204045174\n",
      "정확도 :  0.9818\n",
      "\n",
      "epoch :     20 \n",
      "evg cost :  0.0211543251\n",
      "정확도 :  0.9805\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(20):\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, cv = sess.run([optimizer, cost], feed_dict = {x:batch_xs, y:batch_ys, keep_prob:0.8}) # 해당계층의 전체 노드에서 80프로에 해당하는 노드만 학습에 사용\n",
    "        total_cost += cv\n",
    "    print(\"\\nepoch : \", \"%5d\" % (epoch+1), \"\\nevg cost : \", \"{:.10f}\".format(total_cost/total_batch))\n",
    "    is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "    print(\"정확도 : \", sess.run(accuracy, feed_dict = {x:mnist.test.images, y:mnist.test.labels, keep_prob:1}))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
